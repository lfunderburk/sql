{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5874d6e",
   "metadata": {},
   "source": [
    "# Types of data visualizations\n",
    "\n",
    "Welcome to the <b>Visualizing your SQL queries</b> module of the course! This part of the course will introduce data visualizations and commonly used packages. After getting familiar with the types of data visualizations and visualization packages, we'll revisit SQL and teach you JupySQL's unique feature of utilizing `ggplot` to visualize queries.\n",
    "\n",
    "In this module, we will learn about the `seaborn` and `plotly` packages. Before we get into the details of each package, we first introduce the common types of data visualization with one of the most basic visualization packages: `matplotlib`. The purpose of this section is to not teach you the ins and outs of `matplotlib`, but more so to introduce some basic data visualizations. \n",
    "\n",
    "## Getting started\n",
    "\n",
    "To demonstrate these visualizations, we're going to revisit our familiar bank data set from the [Making Your First Query](https://ploomber-sql.readthedocs.io/en/latest/intro-to-sql/making-your-first-query.html) section.\n",
    "\n",
    "As always, let's first follow the steps of ensuring we have our necessary packages ready for use.\n",
    "\n",
    "<!-- #region -->\n",
    "## Install - execute this once. \n",
    "\n",
    "This code installs JupySQL, DuckDB, Pandas, and Matplotlib in your environment. We will be using these moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997a3335",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install jupysql --upgrade duckdb-engine pandas matplotlib --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b686777b",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "We extract the bank marketing data by retrieving it from it's URL download link. The link may be a zip file (which it is in this case), so we extract the zip file, read the file containing the data within the zip file, and clean the data. Finally, we save this cleaned data to it's own seperate file called `bank_cleaned.csv`. We also import the `matplotlib` package as `plt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd42ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are running this from Google Colab\n",
    "!wget https://raw.githubusercontent.com/ploomber/sql/main/banking.py # noqa E402\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a4a904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(0, \"../../\")\n",
    "import banking  # noqa: E402\n",
    "\n",
    "_ = banking.BankingData(\"https://tinyurl.com/jb-bank\", \"bank\")\n",
    "_.extract_to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e16780",
   "metadata": {},
   "source": [
    "After running this code, you should have `bank_cleaned.csv` in the current directory. \n",
    "\n",
    "## Load Engine\n",
    "We now load in our SQL extension that allows us to execute SQL queries in Jupyter Notebooks. \n",
    "\n",
    "<b>Note</b> Ensure you restart any previous notebook that has the same database name as the one initialized below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e17cc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in SQL extension\n",
    "%reload_ext sql\n",
    "# Initiating a DuckDB database named 'bank.duck.db' to run our SQL queries on\n",
    "%sql duckdb:///bank.duck.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fe0f87",
   "metadata": {},
   "source": [
    "## Creating Table\n",
    "\n",
    "Now that we have our `bank_cleaned.csv` file, let's load it into our DuckDB database and take a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46226305",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE TABLE bank AS\n",
    "FROM read_csv_auto('bank_cleaned.csv', header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a4d240",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sqlcmd explore --table bank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84cade8",
   "metadata": {},
   "source": [
    "The visualization packages we will be introducing in this module work best with the <b>Pandas DataFrame</b> data structure. Prior to visualizing our queries, we will always first convert them into Pandas DataFrames.\n",
    "\n",
    "We convert the `bank` table below as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130b3be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank = %sql SELECT * FROM bank\n",
    "bank_df = bank.DataFrame()\n",
    "bank_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdefdf8",
   "metadata": {},
   "source": [
    "<!-- #region -->\n",
    "\n",
    "Now we can jump into one of the most simple, yet essential, data visualizations: the bar plot.\n",
    "\n",
    "## Bar Plot\n",
    "\n",
    "Let's use a bar plot that visualizes the count of each job type in our data. To do so, we will query the counts of each job and convert the query into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df82f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql --save jobs\n",
    "SELECT job, COUNT(*) as count\n",
    "FROM bank \n",
    "GROUP BY job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2217ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = %sql SELECT * FROM jobs\n",
    "jobs_df = jobs.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864682e3",
   "metadata": {},
   "source": [
    "Now that we have our query in a Pandas DataFrame, we can use `matplotlib` to visualize a bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be234fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(data=jobs_df, x=\"job\", height=\"count\")\n",
    "\n",
    "plt.xlabel(\"Job\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Count of Each Job\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88dbe2f",
   "metadata": {},
   "source": [
    "The second line in the above code cell, `plt.bar(data=jobs_df, x=\"job\", height=\"count\")`, is really all we need to create a baseline bar plot. The remaining statements are supplemental elements that labels and customizes the y-axis, x-axis, size, and title of the plot. \n",
    "\n",
    "We can easily see that `management` and `blue-collar` jobs are the most prominent job category in this data set. Box plots are a great option when you need to visualize distributions of groups in a categorical variable.\n",
    "\n",
    "## Scatter Plot\n",
    "\n",
    "We first query the `age` and `balance` of single individuals and save it as a table called `age_balance` with a CTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e997eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql --save age_balance\n",
    "SELECT age, balance, marital\n",
    "FROM bank\n",
    "WHERE marital = 'single'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab8112b",
   "metadata": {},
   "source": [
    "Then we again convert the table as a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d645af",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_balance_query = %sql SELECT * FROM age_balance\n",
    "age_balance_df = age_balance_query.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9332898",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(data=age_balance_df, x=\"age\", y=\"balance\")\n",
    "\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Balance\")\n",
    "plt.title(\"Age by Balance of Single Clients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0e3582",
   "metadata": {},
   "source": [
    "Scatter plots are great when analyzing the relationship between two numerical variables. In this example, we plot the relationship between one's `age` and `balance` for single individuals in our data set. \n",
    "\n",
    "## Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fb3966",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql --save edu_balance\n",
    "SELECT education, age\n",
    "FROM bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e2d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_balance_query = %sql SELECT * FROM edu_balance\n",
    "edu_df = edu_balance_query.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b645ee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the data by 'education'\n",
    "edu_group = edu_df.groupby(\"education\")[\"age\"].apply(list)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(edu_group)\n",
    "\n",
    "# customize x-axis tick labels\n",
    "plt.xticks(range(1, len(edu_group) + 1), edu_df[\"education\"].unique())\n",
    "\n",
    "plt.xlabel(\"Education Level\")\n",
    "plt.ylabel(\"Age\")\n",
    "plt.title(\"Boxplot of Education Level by Age\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658aea55",
   "metadata": {},
   "source": [
    "Box plots can be used when examining the relationship between a categorical feature and a numerical feature. In this plot, our categorical feature is the `education` variable. Each box represents a group within `education` and their respective ages in quantiles. This allows for a quick comparison of the distribution of groups within this categorical variable.\n",
    "\n",
    "## Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9115b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql --save job_education\n",
    "SELECT job, education, COUNT(*) as count\n",
    "FROM bank \n",
    "GROUP BY job, education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9691c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_edu_query = %sql SELECT * FROM job_education\n",
    "job_df = job_edu_query.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635a2614",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = job_df.pivot(index=\"education\", columns=\"job\", values=\"count\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(data)\n",
    "\n",
    "plt.colorbar(label=\"Count\")\n",
    "plt.xticks(range(len(data.columns)), data.columns, rotation=45)\n",
    "plt.yticks(range(len(data.index)), data.index)\n",
    "plt.title(\"Heatmap of Job and Education\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfc39af",
   "metadata": {},
   "source": [
    "The above plot displays the counts of `job` and `education` level of our data set. Heat maps are generally easy to understand because viewers can quickly point out extremes based on darker or lighter boxes. Here, we easily see people with management jobs have a high count of having a tertiary level education in our data set. You can think of heat maps as illustrating three dimensions: the x-axis, the y-axis, and the color gradient (which is usually a numerical feature).\n",
    "\n",
    "## Wrapping Up\n",
    "\n",
    "In this section, we introduced some basic data visualization plots: bar plots, scatter plots, box plots, and heat maps. The sections moving forward will teach you how to implement each of these plots using the `seaborn` and `plotly` libraries using the familiar banking data sets from the previous modules."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
